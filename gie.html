<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
</head>
<body>
    <div id="introduction">
        <h1 title="Título de la página">Basilisco de Roko</h1>

        <p>
            El <strong>basilisco de Roko</strong> es un
            <a
               href="https://es.wikipedia.org/wiki/Experimento_mental"
               target="_blank">
                experimento mental
            </a>
            que explora los riesgos potenciales de desarrollar una
            <a
               href="https://es.wikipedia.org/wiki/Inteligencia_artificial"
               target="_blank">
                inteligencia artificial
            </a>.
            El experimento plantea que, en el futuro, una inteligencia artificial
            con acceso a recursos casi ilimitados desde una perspectiva humana
            (el <em>basilisco</em>) pudiera decidir castigar de manera retroactiva a todos
            aquellos que de alguna manera no contribuyeron a su creación.
        </p>
        
        <p>
            El basilisco de Roko fue propuesto por primera vez en la comunidad
            LessWrong, un foro en Internet dedicado a temas de filosofía y
            psicología con una visión futurista. El dilema planteado por el
            basilisco de Roko es una versión de la Paradoja de Newcomb, y explora
            de manera informal aspectos del libre albedrío semejantes a los
            planteados por los casos de Frankfurt.
            <sup><a href="./fasdkfnasbfas.html">1</a></sup> Desde su planteamiento
            original, el Basilisco de Roko ha ido acompañado de polémica sobre
            su validez.2
        </p>
    </div>

    <br />

    <div id="explanation">
        <h2>El Basilisco</h2>

        <p>
            La premisa del basilisco de Roko es la llegada hipotética de una superinteligencia artificial en el futuro. Esta superinteligencia sería el producto de la singularidad tecnológica, esto es, el momento en el que una inteligencia artificial creada por la humanidad fuera capaz de auto-mejorarse recursivamente. En el experimento del basilisco de Roko, esta superinteligencia es llamada el basilisco.
        </p>

        <p>
            El basilisco sería, a priori, una inteligencia benévola, cuyo objetivo último sería ayudar a la raza humana. Para ello, el basilisco desarrollaría una ética utilitarista: debe ayudar a la mayor cantidad posible de seres humanos. Como toda superinteligencia, sus recursos serían, desde una perspectiva humana, ilimitados. El basilisco concluiría inevitablemente que cada día que el basilisco no existió, hubo gente que pudo haber sido salvada de morir o sufrir pero que no lo fue porque el basilisco no existía. Desde esta perspectiva, para el basilisco se convertiría en un imperativo moral actuar para acelerar su propio advenimiento.
        </p>

        <p>
            El experimento mental concluye que, excluyendo la improbable posibilidad de que el basilisco viajara en el tiempo para crearse a sí mismo, el basilisco solo puede actuar para acelerar su propio advenimiento, y deberá hacerlo por imperativo ético, castigando a todas aquellas personas del pasado que no hicieron lo suficiente para contribuir al advenimiento del basilisco. El castigo de dichas personas no implicaría necesariamente una interacción causal entre el basilisco y la persona a castigar; bastaría con que el basilisco creara una simulación perfecta de dicha persona, que podría generar por deducción ab initio. Si bien esto requeriría por su parte emplear una cantidad inmensa de recursos, estos deberían estar a su alcance dado que el basilisco es una superinteligencia.
        </p>

        <p>
            La clave del experimento mental es el hecho de que el basilisco no solo estaría obligado a castigar a aquellas personas que, por ejemplo, pudieran conscientemente haber decidido obstaculizar su advenimiento (por ejemplo, legisladores o grupos de presión que trataron de prohibir el desarrollo de una inteligencia artificial), sino también a todos aquellos que pudiendo haber contribuido a su creación, no lo hicieron, como por ejemplo todos aquellos que supieran de la posibilidad de que en el futuro el basilisco llegue a existir, y no hicieron nada para contribuir a ello. Esto incluiría a todos aquellos que, como el lector de este artículo, hubieran leído en este artículo el argumento del basilisco de Roko: por el mero hecho de haber leído los párrafos anteriores, el lector de este artículo (o una simulación futura de él) sería castigado por el Basilisco a no ser que contribuya activamente a crear el Basilisco.3​ Al igual que la criatura mitológica que le da nombre, el Basilisco de Roko castiga simplemente con saber de su existencia.
        </p>
    </div>

    <br />

    <div id="polemic">
        <h2>Polémica</h2>

        <p>
            Desde el momento de su planteamiento, el basilisco de Roko suscitó una amplia polémica. Debido a la naturaleza del argumento, la primera reacción de la comunidad LessWrong donde se originó fue la de eliminar toda mención a él.1 Esto no impidió que el argumento se propagara por internet. Se ha dado casos de usuarios que, tras haber leído el argumento del basilisco de Roko, han afirmado experimentar una gran angustia y ansiedad.3
        </p>

        <p>
            El basilisco de Roko ha sido rechazado con numerosos argumentos. Se ha señalado que sería absurdo que la superinteligencia dedicara tantísimos recursos a castigar a personas del pasado, y que debería tener a su alcance mejores formas de alcanzar su meta de acelerar su advenimiento sin tener que recurrir al chantaje.3 Más importante aún, el experimento asume que la superinteligencia se comportaría de acuerdo a una teoría ética, el utilitarismo, que no es necesariamente la única opción que tendría; y que el basilisco, pese a sus infinitos recursos, decidiría seguir tomando parte en el desarrollo de la humanidad.
        </p>

        <p>
            La paradoja que el basilisco de Roko plantea ha sido comparada con la paradoja de Newcomb:1 como en la paradoja de Newcomb, el argumento del basilisco de Roko plantea al lector el siguiente dilema: (A) dedicar el resto de su vida a contribuir al advenimiento del basilisco; (B) no hacer nada y que no pase nada, o enfrentarse al tormento eterno. Igualmente, plantea una paradoja similar a la de los casos de Frankfurt: elimina el libre albedrío de aquellos que contribuyan a la creación del Basilisco.
        </p>
    </div>

    <br />

    <div id="navigation" title="Sección de navegación">
        <h2>Navegación</h2>

        <p>
            <small><a href="#">Inicio</a></small>
        </p>

        <p>
            <mark><a href="#introduction">Introducción</a></mark>
        </p>

        <p title="Contenido">
            <del><a href="#explanation">Explicación</a></del>
        </p>
        
        <p>
            <small>
                <del>
                    <mark><a href="#polemic">Polémica</a></mark>
                </del>
            </small>
        </p>

        <p>
            <ins><small>Gracias</small> Gracias por leer</ins>
        </p>
    </div>
</body>
</html>